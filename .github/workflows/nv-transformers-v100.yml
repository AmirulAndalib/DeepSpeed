name: nv-transformers-v100

on:
  pull_request:
    paths-ignore:
      - 'docs/**'
      - 'blogs/**'
      - 'deepspeed/inference/v2/**'
      - "tests/unit/inference/v2/**"
  merge_group:
    branches: [ master ]
  schedule:
    - cron: "0 0 * * *"

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  unit-tests:
    runs-on: [self-hosted, nvidia, cu116, v100]

    steps:
      - uses: actions/checkout@v3

      - id: setup-venv
        uses: ./.github/workflows/setup-venv

      - name: Install pytorch
        run: |
          # use the same pytorch version as transformers CI
          pip install -U --cache-dir $TORCH_CACHE torch torchvision --index-url https://download.pytorch.org/whl/cu118
          python -c "import torch; print('torch:', torch.__version__, torch)"
          python -c "import torch; print('CUDA available:', torch.cuda.is_available())"

      - name: Install transformers
        run: |
          git clone https://github.com/huggingface/transformers
          cd transformers
          # if needed switch to the last known good SHA until transformers@master is fixed
          #git checkout e7e9261a2
          git rev-parse --short HEAD
          pip install .[testing]
          # find reqs used in ds integration tests
          find examples/pytorch -regextype posix-egrep -regex '.*(language-modeling|question-answering|summarization|image-classification|text-classification|translation).*/requirements.txt' -exec grep -v 'torch' {} \; | xargs -I {} pip install --upgrade {}
          # force protobuf version due to issues
          pip install "protobuf<4.21.0"

      - name: Install deepspeed
        run: |
          pip install .[dev,autotuning]
          ds_report

      - name: Python environment
        run: |
          pip list

      - name: HF transformers tests
        run: |
          unset TORCH_CUDA_ARCH_LIST # only jit compile for current arch
          cd transformers
          WANDB_DISABLED=true RUN_SLOW=1 pytest $PYTEST_OPTS tests/deepspeed -k "not zero_to_fp32_zero3_qa_mpnet and not zero_to_fp32_zero3_mlm_funnel and not zero_to_fp32_zero3_trans_m2m_100 and not zero_to_fp32_zero3_mlm_flaubert and not zero_to_fp32_zero3_trans_marian and not zero_to_fp32_zero3_clm_prophetnet and not zero_to_fp32_zero3_clas_bert and not zero_to_fp32_zero3_trans_fsmt"
